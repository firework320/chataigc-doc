import{_ as a,c as l,o as s,ag as i}from"./chunks/framework.BHAHxt1l.js";const b=JSON.parse('{"title":"🤖 ChatGLM本地模型部署","description":"","frontmatter":{},"headers":[],"relativePath":"work/third/chatglm.md","filePath":"work/third/chatglm.md","lastUpdated":1737639082000}'),e={name:"work/third/chatglm.md"};function n(h,t,d,r,p,o){return s(),l("div",null,t[0]||(t[0]=[i(`<h1 id="🤖-chatglm本地模型部署" tabindex="-1">🤖 ChatGLM本地模型部署 <a class="header-anchor" href="#🤖-chatglm本地模型部署" aria-label="Permalink to &quot;🤖 ChatGLM本地模型部署&quot;">​</a></h1><h2 id="🚀-chatglm2-6b" tabindex="-1">🚀 ChatGLM2-6B <a class="header-anchor" href="#🚀-chatglm2-6b" aria-label="Permalink to &quot;🚀 ChatGLM2-6B&quot;">​</a></h2><h3 id="📖-chatglm2-6b-简介" tabindex="-1">📖 ChatGLM2-6B 简介 <a class="header-anchor" href="#📖-chatglm2-6b-简介" aria-label="Permalink to &quot;📖 ChatGLM2-6B 简介&quot;">​</a></h3><p>ChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，具体介绍可参阅 <a href="https://github.com/THUDM/ChatGLM2-6B" target="_blank" rel="noreferrer">ChatGLM2-6B 项目主页</a></p><div class="warning custom-block"><p class="custom-block-title">⚠️ 注意</p><p>ChatGLM2-6B 权重对学术研究完全开放，在获得官方的书面许可后，亦允许商业使用。本教程只是介绍了一种用法，无权给予任何授权！</p></div><h3 id="💻-推荐配置" tabindex="-1">💻 推荐配置 <a class="header-anchor" href="#💻-推荐配置" aria-label="Permalink to &quot;💻 推荐配置&quot;">​</a></h3><p>依据官方数据，同样是生成 8192 长度，量化等级为 FP16 要占用 12.8GB 显存、int8 为 8.1GB 显存、int4 为 5.1GB 显存，量化后会稍微影响性能，但不多。</p><table tabindex="0"><thead><tr><th>类型</th><th>内存</th><th>显存</th><th>硬盘空间</th></tr></thead><tbody><tr><td>fp16</td><td>&gt;=16GB</td><td>&gt;=16GB</td><td>&gt;=25GB</td></tr><tr><td>int8</td><td>&gt;=16GB</td><td>&gt;=9GB</td><td>&gt;=25GB</td></tr><tr><td>int4</td><td>&gt;=16GB</td><td>&gt;=6GB</td><td>&gt;=25GB</td></tr></tbody></table><h3 id="🛠️-源码部署" tabindex="-1">🛠️ 源码部署 <a class="header-anchor" href="#🛠️-源码部署" aria-label="Permalink to &quot;🛠️ 源码部署&quot;">​</a></h3><div class="tip custom-block"><p class="custom-block-title">💡 提示</p><p>根据上面的环境配置配置好环境，具体教程自行百度； 可参考的部署文章: <a href="https://blog.csdn.net/lovelylord/article/details/132349967" target="_blank" rel="noreferrer">https://blog.csdn.net/lovelylord/article/details/132349967</a></p></div><ul><li><strong>1️⃣ 从GitHub仓库中拉取代码</strong></li></ul><div class="language-bash vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1.从GitHub仓库中拉取代码</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">git</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> clone</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://github.com/THUDM/ChatGLM2-6B</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2.进入下载源码的目录</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ChatGLM2-6B</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><ul><li><p><strong>2️⃣ 下载python文件：</strong> <a href="https://doc.chatmoney.cn/docs/download/glm.zip" target="_blank" rel="noreferrer">📥 点击下载Python文件</a></p><ul><li>得到两个文件: openai_ai.py 和 requirements.txt</li><li>把这两个文件替换到 ChatGLM2-6B 目录里面</li></ul></li><li><p><strong>3️⃣ 安装依赖：</strong> <strong>​<code>pip install -r requirments.txt</code>​</strong></p><ul><li>建议使用python的虚拟环境,以免产生一些不必要的麻烦。</li></ul></li><li><p><strong>4️⃣ 运行项目：</strong> <strong>​<code>python openai_api.py --model 16</code>​</strong> <strong>这里的数字根据上面的配置进行选择。</strong></p><ul><li>然后等待模型下载，直到模型加载完毕为止。如果出现报错先问百度。</li><li>这里可能需要科学上网</li></ul></li><li><p><strong>5️⃣ 启动成功后应该会显示如下地址：</strong></p></li></ul><div class="tip custom-block"><p class="custom-block-title">💡 提示</p><p>这里的 <a href="http://0.0.0.0:8000/" target="_blank" rel="noreferrer">http://0.0.0.0:8000</a> 就是连接地址。</p></div><p><img src="https://doc.chatmoney.cn/docs/images/general/third-deployment/chat-glm/chatglm-start.png" alt="启动界面"></p><h3 id="⚙️-关于-openai-api-py-启动参数" tabindex="-1">⚙️ 关于 openai_api.py 启动参数 <a class="header-anchor" href="#⚙️-关于-openai-api-py-启动参数" aria-label="Permalink to &quot;⚙️ 关于 openai_api.py 启动参数&quot;">​</a></h3><table tabindex="0"><thead><tr><th>参数名</th><th>可选值</th><th>默认值</th></tr></thead><tbody><tr><td>--device</td><td>cuda=显卡运行, cpu=cpu运行</td><td>cuda</td></tr><tr><td>--path</td><td>local=本地下载的模型运行, thudm=线上自动下载</td><td>thudm</td></tr><tr><td>--model</td><td>4=chatglm2-6b-int4, 8=chatglm2-6b-int8, 16=chatglm2-6b</td><td>16</td></tr></tbody></table><ul><li>📝 说明: <ul><li>如果你 <code>--path</code> 参数设置为 local, 那需要你先把模型下载下来, 放到 ChatGLM2-6B/models 目录下</li><li>比如: ChatGLM2-6B/models/chatglm2-6b-int4</li><li>然后再去运行: <code>python openai_api.py --model 4 --path local</code></li></ul></li></ul><h3 id="🧪-接口测试" tabindex="-1">🧪 接口测试 <a class="header-anchor" href="#🧪-接口测试" aria-label="Permalink to &quot;🧪 接口测试&quot;">​</a></h3><p><img src="https://doc.chatmoney.cn/docs/images/general/third-deployment/chat-glm/chatglm-post.png" alt="接口测试"></p><h3 id="🔗-接入到系统" tabindex="-1">🔗 接入到系统 <a class="header-anchor" href="#🔗-接入到系统" aria-label="Permalink to &quot;🔗 接入到系统&quot;">​</a></h3><p><img src="https://doc.chatmoney.cn/docs/images/general/third-deployment/chat-glm/chatglm-set.png" alt="系统接入"></p><h2 id="🚀-chatglm3-6b" tabindex="-1">🚀 ChatGLM3-6B <a class="header-anchor" href="#🚀-chatglm3-6b" aria-label="Permalink to &quot;🚀 ChatGLM3-6B&quot;">​</a></h2><div class="warning custom-block"><p class="custom-block-title">⚠️ 注意</p><p>部署方案和ChatGLM2-6B的方式基本上是一样的。</p></div><ul><li><strong>1️⃣ 从GitHub仓库中拉取代码</strong></li></ul><div class="language-bash vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1.从GitHub仓库中拉取代码</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">https://github.com/THUDM/ChatGLM3</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2.进入下载源码的目录</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">cd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ChatGLM3-6B</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>// ... 中间部分保持不变 ...</p><ul><li><strong>8️⃣ 关于 openai_api.py 启动参数</strong></li></ul><table tabindex="0"><thead><tr><th>参数名</th><th>可选值</th><th>默认值</th></tr></thead><tbody><tr><td>--device</td><td>cuda=显卡运行, cpu=cpu运行</td><td>cuda</td></tr><tr><td>--path</td><td>local=本地下载的模型运行, thudm=线上自动下载</td><td>thudm</td></tr><tr><td>--model</td><td>4=量化模型, 16=chatglm3-6b, 32=chatglm2-6b-32k, 128=chatglm2-6b-32k</td><td>4</td></tr></tbody></table><ul><li>📝 说明: <ul><li>如果你 <code>--path</code> 参数设置为 local, 那需要你先把模型下载下来, 放到 ChatGLM2-6B/models 目录下</li><li>比如: ChatGLM3-6B/models/chatglm3-6b</li><li>然后再去运行: <code>python openai_api.py --model 4 --path local</code></li><li>💡 温馨小提示：GLM3不再像之前GLM2那样单独提供量化版本模型下载，现在是量化模型直接继承在 chatglm3-6b模型上，使用运行命令作为区分。</li></ul></li></ul>`,30)]))}const g=a(e,[["render",n]]);export{b as __pageData,g as default};
